```cpp
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <cuda_runtime.h>
#include <math.h>
#include <iostream>

#define N 10000000  // å‘é‡å¤§å°ï¼š1000 ä¸‡
#define BLOCK_SIZE_1D 1024  // 1D çº¿ç¨‹å—å¤§å°
#define BLOCK_SIZE_3D_X 16  // 3D çº¿ç¨‹å—åœ¨ x æ–¹å‘çš„ç»´åº¦
#define BLOCK_SIZE_3D_Y 8   // 3D çº¿ç¨‹å—åœ¨ y æ–¹å‘çš„ç»´åº¦
#define BLOCK_SIZE_3D_Z 8   // 3D çº¿ç¨‹å—åœ¨ z æ–¹å‘çš„ç»´åº¦ï¼ˆ16*8*8=1024 çº¿ç¨‹ï¼‰

// CPU å®ç°çš„å‘é‡åŠ æ³•
void vector_add_cpu(float *a, float *b, float *c, int n) {
    for (int i = 0; i < n; i++) {
        c[i] = a[i] + b[i];
    }
}

// GPU å®ç°çš„ 1D å‘é‡åŠ æ³•å†…æ ¸
__global__ void vector_add_gpu_1d(float *a, float *b, float *c, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;  // è®¡ç®—å…¨å±€çº¿ç¨‹ç´¢å¼•
    if (i < n) {
        c[i] = a[i] + b[i];  // æ¯ä¸ªçº¿ç¨‹è®¡ç®—ä¸€ä¸ªå…ƒç´ çš„åŠ æ³•
    }
}

// GPU å®ç°çš„ 3D å‘é‡åŠ æ³•å†…æ ¸
__global__ void vector_add_gpu_3d(float *a, float *b, float *c, int nx, int ny, int nz) {
    // ä¸‰ç»´çº¿ç¨‹ç´¢å¼•
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    int k = blockIdx.z * blockDim.z + threadIdx.z;

    if (i < nx && j < ny && k < nz) {
        // å°† 3D ç´¢å¼•æ˜ å°„ä¸º 1D ç´¢å¼•
        int idx = i + j * nx + k * nx * ny;
        if (idx < nx * ny * nz) {
            c[idx] = a[idx] + b[idx];
        }
    }
}

// å‘é‡åˆå§‹åŒ–ä¸ºéšæœºæµ®ç‚¹æ•°
void init_vector(float *vec, int n) {
    for (int i = 0; i < n; i++) {
        vec[i] = (float)rand() / RAND_MAX;
    }
}

// è·å–å½“å‰æ—¶é—´ï¼ˆç§’ï¼‰
double get_time() {
    struct timespec ts;
    clock_gettime(CLOCK_MONOTONIC, &ts);
    return ts.tv_sec + ts.tv_nsec * 1e-9;
}

int main() {
    // ä¸»æœºå†…å­˜æŒ‡é’ˆ
    float *h_a, *h_b, *h_c_cpu, *h_c_gpu_1d, *h_c_gpu_3d;

    // è®¾å¤‡å†…å­˜æŒ‡é’ˆ
    float *d_a, *d_b, *d_c_1d, *d_c_3d;

    // åˆ†é…å¤§å°
    size_t size = N * sizeof(float);

    // åˆ†é…ä¸»æœºå†…å­˜
    h_a = (float*)malloc(size);
    h_b = (float*)malloc(size);
    h_c_cpu = (float*)malloc(size);
    h_c_gpu_1d = (float*)malloc(size);
    h_c_gpu_3d = (float*)malloc(size);

    // åˆå§‹åŒ–è¾“å…¥å‘é‡
    srand(time(NULL));
    init_vector(h_a, N);
    init_vector(h_b, N);

    // åˆ†é…è®¾å¤‡å†…å­˜
    cudaMalloc(&d_a, size);
    cudaMalloc(&d_b, size);
    cudaMalloc(&d_c_1d, size);
    cudaMalloc(&d_c_3d, size);

    // å°†ä¸»æœºæ•°æ®å¤åˆ¶åˆ°è®¾å¤‡
    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);

    // é…ç½® GPU 1D ç½‘æ ¼å¤§å°
    int num_blocks_1d = (N + BLOCK_SIZE_1D - 1) / BLOCK_SIZE_1D;

    // é…ç½® GPU 3D ç½‘æ ¼å¤§å°
    int nx = 100, ny = 100, nz = 1000;  // nx * ny * nz = 10^7
    dim3 block_size_3d(BLOCK_SIZE_3D_X, BLOCK_SIZE_3D_Y, BLOCK_SIZE_3D_Z);
    dim3 num_blocks_3d(
        (nx + block_size_3d.x - 1) / block_size_3d.x,
        (ny + block_size_3d.y - 1) / block_size_3d.y,
        (nz + block_size_3d.z - 1) / block_size_3d.z
    );

    // é¢„çƒ­è¿è¡Œï¼Œé¿å…é¦–æ¬¡æ‰§è¡Œå¸¦æ¥çš„å»¶è¿Ÿ
    printf("Performing warm-up runs...\n");
    for (int i = 0; i < 3; i++) {
        vector_add_cpu(h_a, h_b, h_c_cpu, N);  // CPU
        vector_add_gpu_1d<<<num_blocks_1d, BLOCK_SIZE_1D>>>(d_a, d_b, d_c_1d, N);  // GPU 1D
        vector_add_gpu_3d<<<num_blocks_3d, block_size_3d>>>(d_a, d_b, d_c_3d, nx, ny, nz);  // GPU 3D
        cudaDeviceSynchronize();
    }

    // CPU åŸºå‡†æµ‹è¯•
    printf("Benchmarking CPU implementation...\n");
    double cpu_total_time = 0.0;
    for (int i = 0; i < 5; i++) {
        double start_time = get_time();
        vector_add_cpu(h_a, h_b, h_c_cpu, N);
        double end_time = get_time();
        cpu_total_time += end_time - start_time;
    }
    double cpu_avg_time = cpu_total_time / 5.0;

    // GPU 1D åŸºå‡†æµ‹è¯•
    printf("Benchmarking GPU 1D implementation...\n");
    double gpu_1d_total_time = 0.0;
    for (int i = 0; i < 100; i++) {
        cudaMemset(d_c_1d, 0, size);  // æ¸…ç©ºç»“æœå†…å­˜
        double start_time = get_time();
        vector_add_gpu_1d<<<num_blocks_1d, BLOCK_SIZE_1D>>>(d_a, d_b, d_c_1d, N);
        cudaDeviceSynchronize();
        double end_time = get_time();
        gpu_1d_total_time += end_time - start_time;
    }
    double gpu_1d_avg_time = gpu_1d_total_time / 100.0;

    // æ ¡éªŒ GPU 1D ç»“æœ
    cudaMemcpy(h_c_gpu_1d, d_c_1d, size, cudaMemcpyDeviceToHost);
    bool correct_1d = true;
    for (int i = 0; i < N; i++) {
        if (fabs(h_c_cpu[i] - h_c_gpu_1d[i]) > 1e-4) {
            correct_1d = false;
            std::cout << i << " cpu: " << h_c_cpu[i] << " != " << h_c_gpu_1d[i] << std::endl;
            break;
        }
    }
    printf("1D Results are %s\n", correct_1d ? "correct" : "incorrect");

    // GPU 3D åŸºå‡†æµ‹è¯•
    printf("Benchmarking GPU 3D implementation...\n");
    double gpu_3d_total_time = 0.0;
    for (int i = 0; i < 100; i++) {
        cudaMemset(d_c_3d, 0, size);  // æ¸…ç©ºç»“æœå†…å­˜
        double start_time = get_time();
        vector_add_gpu_3d<<<num_blocks_3d, block_size_3d>>>(d_a, d_b, d_c_3d, nx, ny, nz);
        cudaDeviceSynchronize();
        double end_time = get_time();
        gpu_3d_total_time += end_time - start_time;
    }
    double gpu_3d_avg_time = gpu_3d_total_time / 100.0;

    // æ ¡éªŒ GPU 3D ç»“æœ
    cudaMemcpy(h_c_gpu_3d, d_c_3d, size, cudaMemcpyDeviceToHost);
    bool correct_3d = true;
    for (int i = 0; i < N; i++) {
        if (fabs(h_c_cpu[i] - h_c_gpu_3d[i]) > 1e-4) {
            correct_3d = false;
            std::cout << i << " cpu: " << h_c_cpu[i] << " != " << h_c_gpu_3d[i] << std::endl;
            break;
        }
    }
    printf("3D Results are %s\n", correct_3d ? "correct" : "incorrect");

    // è¾“å‡ºæ€§èƒ½æµ‹è¯•ç»“æœ
    printf("CPU average time: %f milliseconds\n", cpu_avg_time * 1000);
    printf("GPU 1D average time: %f milliseconds\n", gpu_1d_avg_time * 1000);
    printf("GPU 3D average time: %f milliseconds\n", gpu_3d_avg_time * 1000);
    printf("Speedup (CPU vs GPU 1D): %fx\n", cpu_avg_time / gpu_1d_avg_time);
    printf("Speedup (CPU vs GPU 3D): %fx\n", cpu_avg_time / gpu_3d_avg_time);
    printf("Speedup (GPU 1D vs GPU 3D): %fx\n", gpu_1d_avg_time / gpu_3d_avg_time);

    // é‡Šæ”¾å†…å­˜
    free(h_a);
    free(h_b);
    free(h_c_cpu);
    free(h_c_gpu_1d);
    free(h_c_gpu_3d);
    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c_1d);
    cudaFree(d_c_3d);

    return 0;
}
```

---
---
---



ä»¥ä¸‹æ˜¯ä½ æä¾›çš„ **CUDA å‘é‡åŠ æ³•ç¨‹åºåˆ†æ** æŒ‰ç…§ä½ æ‰€éœ€çš„ç»“æ„æ•´ç†ã€æç‚¼å’Œè¡¥å……ï¼Œä¾›ä½ å‚è€ƒæˆ–ä½œä¸ºæ•™å­¦/æ–‡æ¡£ä½¿ç”¨ã€‚

---

## ğŸ§© **CUDA å‘é‡åŠ æ³•ç¨‹åºæ¦‚è¿°**

è¯¥ç¨‹åºå®Œæˆäº†ä¸¤ä¸ªé•¿åº¦ä¸º **1 åƒä¸‡ï¼ˆ10â·ï¼‰** çš„ `float` å‘é‡é€å…ƒç´ åŠ æ³•æ“ä½œï¼Œåˆ†åˆ«ä½¿ç”¨ **CPU** å’Œä¸¤ç§ **GPU å†…æ ¸å®ç°ï¼ˆ1D å’Œ 3Dï¼‰**ï¼Œå¹¶è¿›è¡Œï¼š

* **æ€§èƒ½åŸºå‡†æµ‹è¯•**ï¼ˆBenchmarkï¼‰
* **ç»“æœæ­£ç¡®æ€§éªŒè¯**
* **åŠ é€Ÿæ¯”åˆ†æ**

---

## ğŸ”© **å®ä¸å‚æ•°è®¾å®š**

```cpp
#define N 10000000         // å‘é‡é•¿åº¦
#define BLOCK_SIZE_1D 1024 // 1D çº¿ç¨‹å—å¤§å°
#define BLOCK_SIZE_3D_X 16
#define BLOCK_SIZE_3D_Y 8
#define BLOCK_SIZE_3D_Z 8  // æ¯ä¸ª 3D çº¿ç¨‹å—å…± 16*8*8=1024 çº¿ç¨‹
```

* ç”¨ 3D block æ¨¡æ‹Ÿ volume gridï¼š`100 * 100 * 1000 = 10â·`

---

## ğŸ§  **ä¸»è¦å‡½æ•°**

### âœ… `vector_add_cpu`

> ä½¿ç”¨ç»å…¸çš„é€å…ƒç´ å¾ªç¯ï¼š

```cpp
for (int i = 0; i < n; i++) {
    c[i] = a[i] + b[i];
}
```

ç”¨äºåŸºå‡†ç»“æœå’Œæ­£ç¡®æ€§éªŒè¯ã€‚

---

### âœ… `__global__ void vector_add_gpu_1d`

```cpp
int i = blockIdx.x * blockDim.x + threadIdx.x;
if (i < n) {
    c[i] = a[i] + b[i];
}
```

* **çº¿æ€§ç´¢å¼•è®¡ç®—**
* æ¯ä¸ªçº¿ç¨‹å¤„ç†ä¸€ä¸ª `a[i] + b[i]`
* åŠ è¾¹ç•Œä¿æŠ¤é˜²æ­¢è¶Šç•Œè®¿é—®

---

### âœ… `__global__ void vector_add_gpu_3d`

```cpp
int i = blockIdx.x * blockDim.x + threadIdx.x;
int j = blockIdx.y * blockDim.y + threadIdx.y;
int k = blockIdx.z * blockDim.z + threadIdx.z;
int idx = i + j * nx + k * nx * ny;
```

* æ˜¾å¼è®¡ç®— `3D â†’ 1D` æ˜ å°„ä¸‹æ ‡ `idx`
* æœ€åè®¿é—® `a[idx] + b[idx]`ï¼Œå†™å…¥ `c[idx]`
* æ·»åŠ  `idx < N` æ£€æŸ¥ä»¥é˜²å†—ä½™çº¿ç¨‹æ‰§è¡Œæ— æ•ˆè®¿é—®

---

## ğŸ§ª **æ—¶é—´æµ‹é‡ä¸æ‰§è¡Œé€»è¾‘**

### âœ… `double get_time()`

ä½¿ç”¨ `clock_gettime(CLOCK_MONOTONIC)` å®ç°é«˜ç²¾åº¦è®¡æ—¶ã€‚

> æ›´æ¨èä½¿ç”¨ CUDA åŸç”Ÿè®¡æ—¶ï¼š`cudaEventRecord()` ï¼ˆä¸‹é¢ä¼šå»ºè®®æ”¹è¿›ï¼‰

---

### âœ… Warm-up

```cpp
for (int i = 0; i < 3; i++) {
    ...
    cudaDeviceSynchronize();
}
```

* é¿å…é¦–æ¬¡è¿è¡Œå¸¦æ¥çš„å»¶è¿Ÿï¼ˆå¦‚ kernel JIT ç¼–è¯‘ã€context åˆå§‹åŒ–ï¼‰

---

### âœ… Benchmark æµ‹è¯•é€»è¾‘

* CPUï¼šæ‰§è¡Œ 5 æ¬¡å–å¹³å‡
* GPUï¼šæ‰§è¡Œ 100 æ¬¡å–å¹³å‡ï¼ˆæ›´ç¨³å®šï¼‰

```cpp
cudaMemset(...)     // æ¸…é›¶ç»“æœåŒº
kernel<<<...>>>()   // æ‰§è¡Œ kernel
cudaDeviceSynchronize();
```

---

## ğŸ§ª **æ­£ç¡®æ€§éªŒè¯**

```cpp
fabs(h_c_cpu[i] - h_c_gpu[i]) > 1e-4
```

* æ§åˆ¶åœ¨ `1e-4` çš„å•ç²¾åº¦è¯¯å·®èŒƒå›´
* é‡é”™å³åœæ­¢è¾“å‡ºå·®å€¼ï¼ˆè°ƒè¯•ç”¨ï¼‰

---

## ğŸ“ˆ **è¾“å‡ºæ€§èƒ½æŒ‡æ ‡**

```text
CPU average time: ...
GPU 1D average time: ...
GPU 3D average time: ...
Speedup (CPU vs GPU 1D): ...
```

**è¯´æ˜ï¼š**

* å¯¹æ¯” CPU ä¸ GPU åŠ é€Ÿæ¯”
* åŒæ—¶æ¯”è¾ƒ 1D ä¸ 3D é…ç½®çš„ GPU æ•ˆç‡å·®å¼‚

---

## ğŸš€ **è¿›é˜¶ä¼˜åŒ–å»ºè®®**

| æ–¹å‘            | ä¼˜åŒ–å»ºè®®                                                            |
| ------------- | --------------------------------------------------------------- |
| â±ï¸ è®¡æ—¶ç²¾åº¦       | ä½¿ç”¨ `cudaEvent_t` æ›¿ä»£ `clock_gettime`ï¼Œä¸“æµ‹ kernel æ‰§è¡Œæ—¶é—´ï¼Œé¿å…ä¸»æœºå¹²æ‰°       |
| ğŸ’¾ æ•°æ®ä¼ è¾“       | ä½¿ç”¨ pinned memoryï¼ˆé¡µé”å®šå†…å­˜ï¼‰æé«˜ H2D/D2H å¸¦å®½                            |
| ğŸ” å¼‚æ­¥æ‰§è¡Œ       | åˆ©ç”¨ CUDA stream å®ç° memcpy ä¸ kernel çš„ overlap                     |
| ğŸ“ block/grid | åŠ¨æ€è‡ªé€‚åº” blockSizeï¼Œæˆ–å®éªŒ 2D grid æ€§èƒ½è¡¨ç°                                |
| ğŸ§® å†…æ ¸é€»è¾‘       | æ·»åŠ  shared memory ä¼˜åŒ–/é¿å… bank conflictï¼ˆé€‚åˆæ›´å¤æ‚è¿ç®—ï¼‰                   |
| ğŸ“Š æ€§èƒ½åˆ†æ       | ä½¿ç”¨ `nvprof` æˆ– Nsight Compute æŸ¥çœ‹ memory throughputã€occupancy ç­‰æŒ‡æ ‡ |
| ğŸ§¬ æ¨¡æ¿åŒ–æ‰©å±•      | æ¨¡æ¿æ”¯æŒ `float`ã€`double` ç±»å‹å…¼å®¹ï¼ˆfor scientific computingï¼‰            |

---

## ğŸ¯ **æ”¹è¿›ç‰ˆæ—¶é—´æµ‹é‡ï¼ˆæ¨èï¼‰**

```cpp
cudaEvent_t start, stop;
cudaEventCreate(&start);
cudaEventCreate(&stop);

cudaEventRecord(start);
kernel<<<grid, block>>>(...);
cudaEventRecord(stop);
cudaEventSynchronize(stop);

float ms = 0;
cudaEventElapsedTime(&ms, start, stop);
```

* **å•ä½ä¸ºæ¯«ç§’ï¼ˆmsï¼‰**
* æ’é™¤ Host æ§åˆ¶æ—¶é—´ï¼Œåªæµ‹ kernel éƒ¨åˆ†
* å¯¹çŸ­å†…æ ¸å°¤å…¶é‡è¦

---

## âœ… æ€»ç»“çŸ¥è¯†ç‚¹

| æ¦‚å¿µ     | æ¶‰åŠä½ç½®                                    |
| ------ | --------------------------------------- |
| ä¸€ç»´çº¿ç¨‹ç´¢å¼• | `blockIdx.x * blockDim.x + threadIdx.x` |
| ä¸‰ç»´çº¿ç¨‹ç´¢å¼• | `i + j * nx + k * nx * ny`              |
| ç½‘æ ¼ç»´åº¦è®¡ç®— | `(N + BLOCK_SIZE - 1) / BLOCK_SIZE`     |
| ä¸»æœºè®¾å¤‡å†…å­˜ | `malloc / cudaMalloc / cudaMemcpy`      |
| ç»“æœéªŒè¯   | `fabs(cpu - gpu) > Îµ`                   |
| æ€§èƒ½ç»Ÿè®¡   | å–å¹³å‡ + speedup è¾“å‡º                        |

---

æ˜¯å¦éœ€è¦æˆ‘å¸®ä½ ï¼š

* âœ æ”¹å†™ä¸€ä¸ªä½¿ç”¨ `cudaEvent` çš„ç‰ˆæœ¬ï¼Ÿ
* ğŸ§ª æ‰©å±•ä¸º vector multiply / dot productï¼Ÿ
* ğŸ“Š ç”Ÿæˆ Excel/CSV æ ¼å¼çš„åŸºå‡†æµ‹è¯•ç»“æœæ–¹ä¾¿ç»˜å›¾ï¼Ÿ
* ğŸ“Œ ç¼–å†™ä¸€ä¸ªç”¨äº Nsight Profiler åˆ†æçš„ wrapper è„šæœ¬ï¼Ÿ

å¯ä»¥ç»§ç»­æ·±æŒ–å†…æ ¸è°ƒä¼˜ã€CUDA Occupancy åˆ†ææˆ–å®é™…åº”ç”¨åœºæ™¯ï¼ˆå¦‚æ¨èç³»ç»Ÿæˆ–é‡‘èè®¡ç®—ï¼‰æ‹“å±•ã€‚ä½ æƒ³ç»§ç»­å“ªä¸ªæ–¹å‘ï¼Ÿ

---
---


ä½ æåˆ°çš„è¿™æ®µ 3D ç½‘æ ¼æ˜ å°„åˆ° 1D æ•°ç»„çš„ä»£ç ï¼š

```cpp
int i = blockIdx.x * blockDim.x + threadIdx.x;
int j = blockIdx.y * blockDim.y + threadIdx.y;
int k = blockIdx.z * blockDim.z + threadIdx.z;
int idx = i + j * nx + k * nx * ny;
```

ç¡®å®æ˜¯å°†ä¸€ä¸ª **ä¸‰ç»´ç½‘æ ¼ä¸­çš„çº¿ç¨‹ç´¢å¼•** æ˜ å°„åˆ°ä¸€ç»´å†…å­˜æ•°ç»„ç´¢å¼• `idx`ï¼Œç”¨äºè®¿é—® `a[idx]`, `b[idx]`, å¹¶å°†ç»“æœå†™å…¥ `c[idx]`ã€‚æˆ‘ä»¬æ¥é€æ­¥è¯¦ç»†åˆ†æè¿™ä¸ªæ˜ å°„å…¬å¼å’Œä¸ºä»€ä¹ˆéœ€è¦ `if (idx < N)` çš„ä¿æŠ¤é€»è¾‘ã€‚

---

### ğŸ”¢ ä¸€ã€3D ç½‘æ ¼åˆ° 1D ç´¢å¼•æ˜ å°„åŸç†

å‡è®¾æ•°æ®åŸæœ¬æ˜¯ä¸‰ç»´æ’åˆ—çš„å¤§å°ä¸º `nx Ã— ny Ã— nz`ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶ **æŒ‰ z è½´ä¼˜å…ˆå±•å¼€ä¸ºä¸€ç»´æ•°ç»„**ã€‚å±•å¼€é¡ºåºå¦‚ä¸‹ï¼š

```
idx = i + j * nx + k * nx * ny
```

#### æ˜ å°„é¡ºåºè§£é‡Šï¼š

* `i` æ˜¯ **x è½´ç´¢å¼•**ï¼Œå˜åŒ–æœ€å¿«ï¼Œæ§åˆ¶åŒä¸€è¡Œå†…çš„å…ƒç´ ï¼›
* `j` æ˜¯ **y è½´ç´¢å¼•**ï¼Œæ¯å½“ y å¢åŠ ï¼Œç›¸å½“äºè·³è¿‡ `nx` ä¸ªå…ƒç´ ï¼›
* `k` æ˜¯ **z è½´ç´¢å¼•**ï¼Œæ¯å½“ z å¢åŠ ï¼Œç›¸å½“äºè·³è¿‡ `nx * ny` ä¸ªå…ƒç´ ã€‚

è¿™å°±æ˜¯æŒ‰ **z â†’ y â†’ x** é¡ºåºå±•å¹³çš„è§„åˆ™ã€‚è¿™æ ·å¯ä»¥åœ¨ CUDA ä¸­åˆ©ç”¨ 3D ç½‘æ ¼/çº¿ç¨‹ç»„ç»‡æ–¹å¼æ¥å¹¶è¡Œå¤„ç†ä¸‰ç»´é€»è¾‘ç»“æ„æ•°æ®ã€‚

---

### ğŸ›¡ï¸ äºŒã€ä¸ºä½•éœ€è¦ `if (idx < N)` çš„è¾¹ç•Œåˆ¤æ–­

ç”±äºå®é™…çš„ `dim3 gridDim` å’Œ `blockDim` åœ¨è®¡ç®—æ—¶é€šå¸¸æ˜¯é€šè¿‡å‘ä¸Šå–æ•´æ–¹å¼ `(dim + block - 1) / block` å¾—åˆ°çš„ï¼š

```cpp
dim3 num_blocks_3d(
    (nx + block_size_3d.x - 1) / block_size_3d.x,
    (ny + block_size_3d.y - 1) / block_size_3d.y,
    (nz + block_size_3d.z - 1) / block_size_3d.z
);
```

> æ‰€ä»¥çº¿ç¨‹æ€»æ•° `gridDim.x * blockDim.x * gridDim.y * blockDim.y * gridDim.z * blockDim.z` ä¸€å®šä¼š **å¤§äºç­‰äº nx Ã— ny Ã— nz**ã€‚

å› æ­¤ï¼Œå¿…ç„¶ä¼šæœ‰ä¸€äº›çº¿ç¨‹çš„ `(i, j, k)` è¶…è¿‡äº†æ•°æ®è¾¹ç•Œã€‚è™½ç„¶ä½ åœ¨å‰é¢å·²ç»åšäº†ï¼š

```cpp
if (i < nx && j < ny && k < nz) {
    //...
}
```

ç†è®ºä¸Šè¿™å°±è¶³å¤Ÿé¿å…è¶Šç•Œã€‚

ä½†ä¸ºäº†**è¿›ä¸€æ­¥ä¿æŠ¤å¹¶ä½¿ä»£ç å¯¹æœªæ¥æ›´é€šç”¨**ï¼ŒåŠ ä¸€å±‚æ£€æŸ¥ `if (idx < N)` æ˜¯æ¨èåšæ³•ï¼ŒåŸå› å¦‚ä¸‹ï¼š

#### âœ… é˜²æ­¢è®¿é—®è¶Šç•Œï¼š

* å¦‚æœ `nx Ã— ny Ã— nz` æ°å¥½ä¸ç­‰äº `N`ï¼ˆå®é™…æ•°æ®é‡ï¼‰ï¼Œå¯èƒ½ä¼šæœ‰è¶Šç•Œé£é™©ã€‚

#### âœ… æé«˜å¥å£®æ€§å’Œç§»æ¤æ€§ï¼š

* ä½ å°†æ¥å¯èƒ½è°ƒæ•´ç½‘æ ¼å°ºå¯¸æˆ–ç”¨äºå…¶å®ƒä»»åŠ¡ï¼ˆå¦‚ padding æˆ– batch æ“ä½œï¼‰æ—¶ï¼ŒN â‰  nx \* ny \* nzã€‚
* ä¿è¯é€»è¾‘æ›´æ˜ç¡®ï¼šâ€œæˆ‘åªå¤„ç†æœ‰æ•ˆçš„æ•°æ®èŒƒå›´â€ã€‚

---

### âœ… ä¸‰ã€æ¨èä»£ç å½¢å¼

ç»¼åˆå»ºè®®å¦‚ä¸‹ï¼Œå°†å¤šä½™çº¿ç¨‹è¿‡æ»¤æ‰ï¼š

```cpp
__global__ void vector_add_gpu_3d(float *a, float *b, float *c, int nx, int ny, int nz, int N) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    int k = blockIdx.z * blockDim.z + threadIdx.z;

    if (i < nx && j < ny && k < nz) {
        int idx = i + j * nx + k * nx * ny;
        if (idx < N) {
            c[idx] = a[idx] + b[idx];
        }
    }
}
```

> âš ï¸ åˆ«å¿˜äº† `N` å‚æ•°è¦åœ¨è°ƒç”¨ kernel æ—¶ä¼ å…¥ã€‚

---

### ğŸ“Œ æ€»ç»“

| æ£€æŸ¥é¡¹                                   | ä½œç”¨                        |
| ------------------------------------- | ------------------------- |
| `i < nx && j < ny && k < nz`          | è¿‡æ»¤æ‰å¤šå‡ºæ¥çš„çº¿ç¨‹ï¼ˆé€»è¾‘ä¸Šä¸å¯¹åº”å®é™…æ•°æ®ç‚¹ï¼‰    |
| `idx < N`                             | å¤šä¸€å±‚ä¿æŠ¤ï¼Œé˜²æ­¢éæ³•å†…å­˜è®¿é—®ï¼Œæé«˜ä»£ç é²æ£’æ€§    |
| æ˜ å°„å…¬å¼ `idx = i + j * nx + k * nx * ny` | å°† 3D åæ ‡æ˜ å°„ä¸ºä¸€ç»´æ•°ç»„ä¸‹æ ‡ï¼Œé€‚é…çº¿æ€§å†…å­˜ç»“æ„ |

å¦‚æœä½ è¿˜æƒ³è¿›ä¸€æ­¥è°ƒä¼˜çº¿ç¨‹å¸ƒå±€æˆ–ç¼“å­˜ä½¿ç”¨æ•ˆç‡ï¼Œä¹Ÿå¯ä»¥è€ƒè™‘ shared memoryã€warp-level primitives ç­‰é«˜çº§æŠ€å·§ã€‚éœ€è¦çš„è¯æˆ‘å¯ä»¥ç»§ç»­è®²è§£ã€‚






