ä¸‹é¢æ˜¯ä½ æä¾›çš„ CUDA çŸ©é˜µä¹˜æ³•ä»£ç ï¼Œ**å·²æ·»åŠ è¯¦ç»†ä¸­æ–‡æ³¨é‡Š**ï¼ŒåŒ…æ‹¬ CPU/GPU å®ç°ã€åˆå§‹åŒ–ã€è®¡æ—¶ç­‰éƒ¨åˆ†ï¼Œé€‚åˆå­¦ä¹ å’Œè°ƒè¯•ä½¿ç”¨ï¼š

```cpp
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <cuda_runtime.h>

// å®šä¹‰çŸ©é˜µç»´åº¦
#define M 256  // A å’Œ C çš„è¡Œæ•°
#define K 512  // A çš„åˆ—æ•°ï¼ŒB çš„è¡Œæ•°
#define N 256  // B å’Œ C çš„åˆ—æ•°
#define BLOCK_SIZE 32  // CUDA æ¯ä¸ªçº¿ç¨‹å—çš„å°ºå¯¸

// ==================== CPU å®ç°çŸ©é˜µä¹˜æ³• ====================
void matmul_cpu(float *A, float *B, float *C, int m, int k, int n) {
    for (int i = 0; i < m; i++) {         // éå† C çš„æ¯ä¸€è¡Œ
        for (int j = 0; j < n; j++) {     // éå† C çš„æ¯ä¸€åˆ—
            float sum = 0.0f;
            for (int l = 0; l < k; l++) { // å†…ç§¯è¿ç®—
                sum += A[i * k + l] * B[l * n + j];
            }
            C[i * n + j] = sum;
        }
    }
}

// ==================== GPU æ ¸å‡½æ•°å®ç°çŸ©é˜µä¹˜æ³• ====================
__global__ void matmul_gpu(float *A, float *B, float *C, int m, int k, int n) {
    int row = blockIdx.y * blockDim.y + threadIdx.y; // å½“å‰çº¿ç¨‹è®¡ç®—çš„è¡Œå·
    int col = blockIdx.x * blockDim.x + threadIdx.x; // å½“å‰çº¿ç¨‹è®¡ç®—çš„åˆ—å·

    if (row < m && col < n) {
        float sum = 0.0f;
        for (int l = 0; l < k; l++) {
            sum += A[row * k + l] * B[l * n + col]; // æ‰§è¡Œå†…ç§¯
        }
        C[row * n + col] = sum; // å†™å…¥ç»“æœ
    }
}

// ==================== éšæœºåˆå§‹åŒ–çŸ©é˜µå…ƒç´  ====================
void init_matrix(float *mat, int rows, int cols) {
    for (int i = 0; i < rows * cols; i++) {
        mat[i] = (float)rand() / RAND_MAX; // éšæœºæµ®ç‚¹æ•° [0, 1)
    }
}

// ==================== è·å–å½“å‰ç³»ç»Ÿæ—¶é—´ï¼ˆç§’ï¼‰ ====================
double get_time() {
    struct timespec ts;
    clock_gettime(CLOCK_MONOTONIC, &ts); // é«˜ç²¾åº¦è®¡æ—¶
    return ts.tv_sec + ts.tv_nsec * 1e-9;
}

// ==================== ä¸»å‡½æ•°å…¥å£ ====================
int main() {
    // ä¸»æœºç«¯æŒ‡é’ˆ
    float *h_A, *h_B, *h_C_cpu, *h_C_gpu;

    // è®¾å¤‡ç«¯æŒ‡é’ˆ
    float *d_A, *d_B, *d_C;

    // è®¡ç®—æ‰€éœ€å†…å­˜å¤§å°
    int size_A = M * K * sizeof(float);
    int size_B = K * N * sizeof(float);
    int size_C = M * N * sizeof(float);

    // åˆ†é…ä¸»æœºå†…å­˜
    h_A = (float*)malloc(size_A);
    h_B = (float*)malloc(size_B);
    h_C_cpu = (float*)malloc(size_C);
    h_C_gpu = (float*)malloc(size_C);

    // åˆå§‹åŒ–è¾“å…¥çŸ©é˜µ
    srand(time(NULL));
    init_matrix(h_A, M, K);
    init_matrix(h_B, K, N);

    // åˆ†é…è®¾å¤‡å†…å­˜
    cudaMalloc(&d_A, size_A);
    cudaMalloc(&d_B, size_B);
    cudaMalloc(&d_C, size_C);

    // å°†æ•°æ®ä»ä¸»æœºå¤åˆ¶åˆ°è®¾å¤‡
    cudaMemcpy(d_A, h_A, size_A, cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, h_B, size_B, cudaMemcpyHostToDevice);

    // å®šä¹‰çº¿ç¨‹å—ç»´åº¦å’Œç½‘æ ¼ç»´åº¦ï¼ˆè¦†ç›–æ‰€æœ‰è¾“å‡ºå…ƒç´ ï¼‰
    dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);  // æ¯ä¸ªçº¿ç¨‹å— BLOCK_SIZE x BLOCK_SIZE
    dim3 gridDim((N + BLOCK_SIZE - 1) / BLOCK_SIZE,
                 (M + BLOCK_SIZE - 1) / BLOCK_SIZE);  // ä¿è¯æ‰€æœ‰å…ƒç´ è¢«è¦†ç›–

    // ========== é¢„çƒ­ï¼ˆwarm-upï¼‰è¿è¡Œï¼Œæå‡åç»­æµ‹é‡ç¨³å®šæ€§ ==========
    printf("Performing warm-up runs...\n");
    for (int i = 0; i < 3; i++) {
        matmul_cpu(h_A, h_B, h_C_cpu, M, K, N); // CPU è¿è¡Œ
        matmul_gpu<<<gridDim, blockDim>>>(d_A, d_B, d_C, M, K, N); // GPU è¿è¡Œ
        cudaDeviceSynchronize(); // ç­‰å¾… GPU æ‰§è¡Œå®Œæ¯•
    }

    // ========== æµ‹é‡ CPU æ‰§è¡Œæ—¶é—´ ==========
    printf("Benchmarking CPU implementation...\n");
    double cpu_total_time = 0.0;
    for (int i = 0; i < 20; i++) {
        double start_time = get_time();
        matmul_cpu(h_A, h_B, h_C_cpu, M, K, N);
        double end_time = get_time();
        cpu_total_time += end_time - start_time;
    }
    double cpu_avg_time = cpu_total_time / 20.0;

    // ========== æµ‹é‡ GPU æ‰§è¡Œæ—¶é—´ ==========
    printf("Benchmarking GPU implementation...\n");
    double gpu_total_time = 0.0;
    for (int i = 0; i < 20; i++) {
        double start_time = get_time();
        matmul_gpu<<<gridDim, blockDim>>>(d_A, d_B, d_C, M, K, N);
        cudaDeviceSynchronize(); // ä¿è¯æ—¶é—´æµ‹é‡å‡†ç¡®
        double end_time = get_time();
        gpu_total_time += end_time - start_time;
    }
    double gpu_avg_time = gpu_total_time / 20.0;

    // ========== è¾“å‡ºæ€§èƒ½ç»“æœ ==========
    printf("CPU average time: %f microseconds\n", cpu_avg_time * 1e6);
    printf("GPU average time: %f microseconds\n", gpu_avg_time * 1e6);
    printf("Speedup: %fx\n", cpu_avg_time / gpu_avg_time);

    // ========== é‡Šæ”¾å†…å­˜ ==========
    free(h_A);
    free(h_B);
    free(h_C_cpu);
    free(h_C_gpu);
    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_C);

    return 0;
}
```

---

### âœ… æ³¨é‡Šé‡ç‚¹æç¤ºï¼š

* **åæ ‡è®¡ç®—æ–¹å¼**ï¼š

  ```cpp
  int row = blockIdx.y * blockDim.y + threadIdx.y;
  int col = blockIdx.x * blockDim.x + threadIdx.x;
  ```

* **æ ¸å‡½æ•°è¦åŠ è¾¹ç•Œåˆ¤æ–­**ï¼Œé˜²æ­¢éæ³•è®¿é—®ã€‚

* **æ—¶é—´æµ‹é‡ä½¿ç”¨ `clock_gettime`**ï¼Œæ¯” `clock()` æ›´å‡†ç¡®ï¼Œé€‚åˆå¾®ç§’çº§æµ‹é‡ã€‚

---

å¦‚æœä½ æ¥ä¸‹æ¥æƒ³è¦ï¼š

* åŠ å…¥ **å…±äº«å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬**ï¼›
* ä½¿ç”¨ **cuBLAS åŠ é€Ÿå¯¹æ¯”**ï¼›
* åŠ å…¥ **éªŒè¯ CPU ä¸ GPU ç»“æœæ˜¯å¦ä¸€è‡´**ï¼›

æˆ‘éƒ½å¯ä»¥å¸®ä½ è¡¥å……ã€‚éœ€è¦å“ªä¸€éƒ¨åˆ†ï¼Œå¯ä»¥ç›´æ¥å‘Šè¯‰æˆ‘ã€‚

---
---


éå¸¸å¥½ï¼ä½ æä¾›çš„ CUDA çŸ©é˜µä¹˜æ³•ç¨‹åºå·²ç»å¾ˆæ¸…æ™°ï¼Œä¸‹é¢æˆ‘å°†**ä»¥æ•™å­¦/æ–‡æ¡£æ–¹å¼**ï¼Œ**ä¸¥æ ¼æŒ‰ç…§ä½ ç»™å‡ºçš„é£æ ¼**ï¼Œå¯¹ä½ çš„çŸ©é˜µä¹˜æ³•ä»£ç è¿›è¡Œç»“æ„åŒ–åˆ†æã€æç‚¼å’Œè¡¥å……å»ºè®®ï¼Œä¾›ä½ æ•´ç†æ–‡æ¡£æˆ–æ•™å­¦ä½¿ç”¨ã€‚

---

## ğŸ§© **CUDA çŸ©é˜µä¹˜æ³•ç¨‹åºæ¦‚è¿°**

æœ¬ç¨‹åºå®ç°äº†ä¸¤ä¸ªçŸ©é˜µ `A (MÃ—K)` ä¸ `B (KÃ—N)` çš„ä¹˜æ³• `C = AÃ—B (MÃ—N)`ï¼Œåˆ†åˆ«ä½¿ç”¨ **CPU ä¸ GPUï¼ˆCUDAï¼‰å®ç°**ã€‚æœ€ç»ˆå¯¹ä¸¤è€…æ‰§è¡Œï¼š

* ğŸ’¡ æ­£ç¡®æ€§éªŒè¯
* ğŸš€ æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ˆå¹³å‡è€—æ—¶ï¼‰
* ğŸ“ˆ åŠ é€Ÿæ¯”åˆ†æ

---

## ğŸ”© **å®ä¸å‚æ•°è®¾å®š**

```cpp
#define M 256      // Aã€C çš„è¡Œæ•°
#define K 512      // A çš„åˆ—æ•°ã€B çš„è¡Œæ•°
#define N 256      // Bã€C çš„åˆ—æ•°
#define BLOCK_SIZE 32  // CUDA block å°ºå¯¸ï¼ˆæ–¹é˜µï¼‰
```

> è¯´æ˜ï¼šè®¾ç½® `BLOCK_SIZE=32` èƒ½å¤Ÿæ˜ å°„åˆ° CUDA Warp ä¼˜åŒ–ç»“æ„ï¼ˆæ¯ä¸ª block 1024 ä¸ªçº¿ç¨‹æœ€å¤§åŒ–èµ„æºåˆ©ç”¨ï¼‰ã€‚

---

## ğŸ§  **ä¸»è¦å‡½æ•°ä¸æ ¸å¿ƒå†…æ ¸**

### âœ… `matmul_cpu`

```cpp
for (int i = 0; i < m; i++)
    for (int j = 0; j < n; j++)
        for (int l = 0; l < k; l++)
            C[i * n + j] += A[i * k + l] * B[l * n + j];
```

* ä¸‰å±‚åµŒå¥—ç»å…¸çŸ©é˜µä¹˜æ³•ã€‚
* è¡Œä¸»åºå±•å¼€ï¼Œé€‚ç”¨äº C é£æ ¼å†…å­˜å¸ƒå±€ã€‚
* ç”¨ä½œ **éªŒè¯ä¸åŸºå‡†å‚è€ƒ**ã€‚

---

### âœ… `__global__ void matmul_gpu`

```cpp
int row = blockIdx.y * blockDim.y + threadIdx.y;
int col = blockIdx.x * blockDim.x + threadIdx.x;

if (row < m && col < n) {
    float sum = 0;
    for (int l = 0; l < k; l++) {
        sum += A[row * k + l] * B[l * n + col];
    }
    C[row * n + col] = sum;
}
```

* æ¯ä¸ªçº¿ç¨‹å¤„ç†ä¸€ä¸ª `C[row][col]` å…ƒç´ ã€‚
* ç´¢å¼•çº¿æ€§è®¡ç®—ï¼Œé€‚é…è¡Œä¸»åºã€‚
* ä½¿ç”¨äºŒç»´ grid/blockï¼šé€‚åˆå¹¶è¡Œç»“æ„ã€‚

---

## ğŸ§ª **æ—¶é—´æµ‹é‡é€»è¾‘**

### âœ… `double get_time()`

```cpp
clock_gettime(CLOCK_MONOTONIC, &ts);
```

* ä½¿ç”¨é«˜ç²¾åº¦ `POSIX` æ—¶é—´ APIã€‚
* æ‰€å¾—ä¸º CPU + GPU host è°ƒç”¨æ§åˆ¶æ€»è€—æ—¶ï¼ˆä¸çº¯ç²¹ä¸ºå†…æ ¸æ—¶é—´ï¼‰ã€‚
* âš ï¸ å»ºè®®ï¼šå®é™…æµ‹ GPU ç”¨ `cudaEvent_t` æ›´åˆç†ï¼ˆä¸‹èŠ‚è¡¥å……ï¼‰ã€‚

---

### âœ… Warm-up çƒ­èº«é˜¶æ®µ

```cpp
for (int i = 0; i < 3; i++) {
    matmul_cpu(...);
    matmul_gpu<<<...>>>(...);
    cudaDeviceSynchronize();
}
```

* é¿å…åˆæ¬¡ kernel JIT ç¼–è¯‘ã€driver load ç­‰å†·å¯åŠ¨æˆæœ¬ã€‚
* æœ‰åŠ©äºç¨³å®šåç»­åŸºå‡†æµ‹è¯•ã€‚

---

## ğŸ“Š **åŸºå‡†æµ‹è¯•éƒ¨åˆ†**

åˆ†åˆ«æ‰§è¡Œ 20 æ¬¡å–å¹³å‡ï¼š

```cpp
// CPU
matmul_cpu(...);

// GPU
matmul_gpu<<<...>>>(...);
cudaDeviceSynchronize();
```

ç»Ÿè®¡å¹³å‡æ‰§è¡Œæ—¶é—´ `avg_time = total_time / 20`ï¼Œå¹¶è¾“å‡ºï¼š

```text
CPU average time: xxx us
GPU average time: xxx us
Speedup: x.xÃ—
```

---

## âœ… CUDA ç½‘æ ¼é…ç½®è®¡ç®—

```cpp
dim3 blockDim(32, 32);
dim3 gridDim((N + 31) / 32, (M + 31) / 32);
```

* æ¯ä¸ª block å« 32Ã—32=1024 ä¸ªçº¿ç¨‹ï¼ˆå•ç²¾åº¦çŸ©é˜µä¹˜æ³•æé™å¹¶è¡Œç»“æ„ï¼‰
* Grid è‡ªåŠ¨è¡¥è¾¹ï¼šç”¨äºä¸æ•´é™¤æ—¶å¯¹è¾¹ç•Œçš„è¦†ç›–
* æ»¡è¶³ launch ä¸Šé™ï¼ˆ1024 threads per blockï¼‰

---

## ğŸ“ æ•°æ®ç»“æ„ä¸å†…å­˜åˆ†é…

```cpp
// Host
float *h_A = malloc(...), *h_B = ..., *h_C_cpu = ..., *h_C_gpu = ...;

// Device
cudaMalloc(&d_A, ...);
cudaMemcpy(d_A, h_A, ..., cudaMemcpyHostToDevice);
```

* CPU å†…å­˜ + GPU å…¨å±€å†…å­˜
* æ‰€æœ‰æ•°æ®é‡‡ç”¨è¡Œä¸»åºå±•å¼€ä¸ºä¸€ç»´
* åˆå§‹åŒ–ä½¿ç”¨ `rand()` è½¬æ¢ä¸º `float` çš„ `0~1` åŒºé—´

---

## ğŸ§ª æ­£ç¡®æ€§éªŒè¯ï¼ˆå»ºè®®è¡¥å……ï¼‰

å°½ç®¡ä½ å½“å‰ç¨‹åºä¸­æ²¡æœ‰å¯¹ `C_gpu` ç»“æœä¸ `C_cpu` ç»“æœè¿›è¡Œè¯¯å·®æ¯”è¾ƒï¼Œå»ºè®®æ·»åŠ ï¼š

```cpp
cudaMemcpy(h_C_gpu, d_C, size_C, cudaMemcpyDeviceToHost);

for (int i = 0; i < M * N; ++i) {
    if (fabs(h_C_gpu[i] - h_C_cpu[i]) > 1e-3f) {
        printf("Mismatch at %d: CPU=%.4f, GPU=%.4f\n", i, h_C_cpu[i], h_C_gpu[i]);
        break;
    }
}
```

---

## ğŸ“ˆ æ€§èƒ½è¾“å‡º

```text
CPU average time: 206.184235 microseconds
GPU average time: 4.152800 microseconds
Speedup: 49.66x
```

* åæ˜ çŸ©é˜µè§„æ¨¡ä¸‹çš„å¹¶è¡Œæ”¶ç›Šã€‚
* é€Ÿåº¦æå‡ä¾èµ– GPU SM æ•°é‡å’Œ memory throughputã€‚

---

## ğŸš€ è¿›é˜¶ä¼˜åŒ–å»ºè®®ï¼ˆå»ºè®®æ·»åŠ  Shared Memory ç‰ˆæœ¬ï¼‰

| æ–¹å‘        | ä¼˜åŒ–å»ºè®®                                                          |
| --------- | ------------------------------------------------------------- |
| ğŸ“Œ å†…æ ¸ä¼˜åŒ–   | ä½¿ç”¨ shared memory tileï¼ˆtile-based GEMMï¼‰ï¼Œå‡å°‘å…¨å±€å†…å­˜è®¿é—®               |
| ğŸ” Stream | åˆ©ç”¨ CUDA stream é‡å  memcpy å’Œè®¡ç®—                                  |
| â±ï¸ è®¡æ—¶ç²¾åº¦   | ç”¨ `cudaEvent_t` æ›´ç²¾ç¡®æµ‹é‡ GPU kernel æ‰§è¡Œæ—¶é—´                         |
| ğŸ“¦ Memory | ä½¿ç”¨ `cudaMallocHost` åˆ†é…é¡µé”å®šå†…å­˜æé«˜ H2D/D2H ä¼ è¾“å¸¦å®½                    |
| ğŸ”¬ åˆ†æå·¥å…·   | åˆ©ç”¨ `nvprof` / Nsight æŸ¥çœ‹ warp stallã€global load efficiency ç­‰æŒ‡æ ‡ |

---

## âœ… æ¨èè®¡æ—¶æ›¿æ¢ï¼ˆGPUï¼‰ğŸ”

```cpp
cudaEvent_t start, stop;
cudaEventCreate(&start);
cudaEventCreate(&stop);

cudaEventRecord(start);
matmul_gpu<<<gridDim, blockDim>>>(...);
cudaEventRecord(stop);
cudaEventSynchronize(stop);

float ms = 0.0f;
cudaEventElapsedTime(&ms, start, stop);
printf("Kernel execution time: %f ms\n", ms);
```

* æ›´ç²¾ç¡®åœ°åªç»Ÿè®¡ **kernel æ—¶é—´**ï¼ˆä¸å« host æ§åˆ¶é€»è¾‘ä¸æ•°æ®ä¼ è¾“ï¼‰
* å»ºè®®æ›¿æ¢ç°æœ‰ `get_time()` çš„ GPU æµ‹é‡æ®µ

---

## âœ… æ€»ç»“çŸ¥è¯†ç‚¹

| æ¦‚å¿µ           | æ¶‰åŠä½ç½®                                     |
| ------------ | ---------------------------------------- |
| çº¿ç¨‹æ˜ å°„ (2D)    | `row = by * BS + ty; col = bx * BS + tx` |
| ä¸‰é‡åµŒå¥— GEMM å®ç° | `for i, j, k` ä¸‰å±‚å¾ªç¯                       |
| GPU åŠ é€Ÿæ ¸å¿ƒ     | CUDA kernel + grid/block é…ç½®              |
| æ­£ç¡®æ€§éªŒè¯        | `fabs(a - b) > Îµ`                        |
| æ€§èƒ½æŒ‡æ ‡         | å¹³å‡æ—¶é—´ï¼ˆå¾®ç§’ï¼‰+ speedup                        |

---

å¦‚æœä½ æ¥ä¸‹æ¥æ‰“ç®—å®ç° **Shared Memory ä¼˜åŒ–ç‰ˆæœ¬**ï¼Œæˆ‘ä¹Ÿå¯ä»¥å¸®ä½ ä»é€»è¾‘ã€ç´¢å¼•è®¾è®¡åˆ°å®Œæ•´ä»£ç è½åœ°ã€‚

éœ€è¦æˆ‘ä¸ºä½ å†™ shared memory ä¼˜åŒ–çš„ç‰ˆæœ¬ï¼Œæˆ–åšæ›´æ·±å±‚æ¬¡ profile ç»“æ„åˆ†æï¼ˆå¦‚ bank conflictã€load efficiencyï¼‰ï¼Œä¹Ÿæ¬¢è¿ç»§ç»­æé—®ã€‚

